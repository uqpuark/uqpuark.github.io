<!DOCTYPE html>
<html>
<head>
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>[DS] 3회차 - 데이터 그룹핑  | 데이터 사이언스 블로그</title>
  <meta name="description" content="대충 넘어 갔던 개념을 자세하게 따져보는 블로그 '[DS] 3회차 - 데이터 그룹핑'을 한 번 살펴보세요.">
  <meta property="og:title" content="[DS] 3회차 - 데이터 그룹핑">
  
  <meta property="og:type" content="article">
  <meta property="article:published_time" content="2021-02-18">
  
  <meta property="og:description" content="대충 넘어 갔던 개념을 자세하게 따져보는 블로그 '[DS] 3회차 - 데이터 그룹핑'을 한 번 살펴보세요.">
  <meta property="og:url" content="https://uqpuark.github.io/dsstudy/3_data_grouping/">
  <meta property="og:site_name" content="데이터 사이언스 블로그">
  
  <meta property="og:image" content="https://uqpuark.github.io/images/thumbnail.png">
  
  
  <link rel="icon" href="/favicon.ico" type="image/x-icon">
  <link rel="canonical" href="https://uqpuark.github.io/dsstudy/3_data_grouping/">
  <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
  <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.6/styles/agate.min.css">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Noto+Sans+KR&display=swap">
  <link rel="stylesheet" href="/css/styles.css">
  <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.6/highlight.min.js"></script>
  <script>hljs.initHighlightingOnLoad();</script>
  
  
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-189694109-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());
    gtag('config', 'UA-189694109-1');
  </script>
  
  
  <script type="text/javascript">
  function toggle_visibility(id) {
    var e = document.getElementById(id);
    if (e.className === 'menu')
      e.className = 'menu hidden';
    else
      e.className = 'menu';
  }
  </script>
</head>
<body>
  <div class="navbar">    
    <div class="logo">
      <a href="/">
        <img src="/images/logo.png" height="35px" />
      </a>
    </div>
    <div class="burger">
      <button onclick="toggle_visibility('menu')">
        <i class="fa fa-bars" aria-hidden="true"></i> 메뉴
      </button>
    </div>
    <div id="menu" class="menu hidden">
      <ul>
        <li><form id="search"
    action='' method="get">
    <label hidden for="search-input">Search site</label>
    <input type="text" id="search-input" name="query"
    placeholder="search or jump to...">
    <input type="submit" value="search">
</form>

</li>
        <li><a href="/categories">카테고리</a></li>
        <li><a href="/tags">태그</a></li>


      </ul>
      <input class="search" id="search-input" type="search" placeholder="검색어" value="">
    </div>
  </div>
  <div class="container">    


<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css" integrity="sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X" crossorigin="anonymous">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.js" integrity="sha384-g7c+Jr9ZivxKLnZTDUhnkOnsh30B4H0rpLUpJ4jAIKs4fnJI+sEnkvrMWph2EDg4" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/contrib/auto-render.min.js" integrity="sha384-mll67QQFJfxn0IYznZYonOWZ644AWYC+Pt2cHqMaRhXVrursRwvLnLaebdGIlYNa" crossorigin="anonymous"
    onload="renderMathInElement(document.body);"></script>


<div class="post">
  <div class="post-title">
    <a href="https://uqpuark.github.io/dsstudy/3_data_grouping/">
      <div class="post-meta">
        <time>2021년 02월 18일 15시 30분</time>
        <h1>[DS] 3회차 - 데이터 그룹핑</h1>
      </div>
    </a>
  </div>
  <section class="post-content">
    <h2 id="section-1-k-nearest-neighbor">Section 1. K-Nearest Neighbor</h2>
<h2 id="section-2-k-means">Section 2. K-Means</h2>
<h2 id="section-3-dimensionality-reduction">Section 3. Dimensionality reduction</h2>
<h2 id="section-4-side-note-bayesian">Section 4. Side Note: Bayesian</h2>
<h3 id="bayesian-vs-frequentist---관점의-차이-계산의-차이-용도의-차이">Bayesian vs. Frequentist - 관점의 차이, 계산의 차이, 용도의 차이</h3>
<h3 id="bayesian-아이디어가-적용되는-간단-예제1---몬티홀-딜레마">Bayesian 아이디어가 적용되는 간단 예제1 - 몬티홀 딜레마</h3>
<ul>
<li>Monty Hall 문제</li>
</ul>
<p>1000개의 문 뒤에 999마리의 양과 1개의 페라리가 있다. 문 하나를 고르고 나면, 사회자가 998개의 문을 열고 난 다음 다시 문을 고를 기회를 준다. 무조건 바꾸는 게 합리적이다.(사회자는 페라리가 몇번 문 뒤에 있는지 아는 상태)<br>
현재 상황 : 1번 문을 골랐고, 사회자가 문을 2 ~ 999번을 열었다. 남은 문은 1번과 1000번</p>
<p>사건 A : n번째 문 뒤에 페라리가 있다.<br>
사건 B : n번째 문을 사회자가 연다.</p>
<p>Prior : P(A), n번째 문 뒤에 페라리가 있을 확률.(1번 뒤에 있을 확률, 2번 뒤에 있을 확률, &hellip; , 1000번 뒤에 있을 확률은 random이기 때문에 각각 1/1000이다.)</p>
<p>Likelihood : P(B|A)</p>
<ul>
<li>1번에 페라리가 있을때 2 ~ 1000번 문(999개)에서 2 ~ 999번 문을 열 확률은 \( { 1 \over {999}C{998} } \),</li>
<li>2번에 페라리가 있을때, 2 ~ 999번 문을 열 확률은 0.(3 ~ 999도 동일)</li>
<li>1000번에 페라리가 있을때, 2 ~ 999번 문을 열 확률은 1.</li>
</ul>
<p>evidence : P(B), 1번을 선택한 상태니깐 열지 않을 것, 따라서 \( { 1 \over 999 } \).</p>
<p>Posterior : P(A|B), 사회자가 문을 다 열였을 때</p>
<ul>
<li>1번 문 뒤에 페라리가 있을 확률 : \( {1 \over 1000} \)</li>
<li>2번 문 뒤에 페라리가 있을 확률 : 0 (3 ~ 999도 동일)</li>
<li>1000번 뒤에 페라리가 있을 확률 : \( {999 \over 1000} \)</li>
</ul>
<p>결론 : 2 ~ 999번에 해당하는 확률이 없어졌을때, 확률이 모두 1000번으로 이동했다. 1000개가 아니라 천만개로 했으면 더 와닿을 것(참고 : <a href="https://www.youtube.com/watch?v=eCrSFFDTGI0">남휘종T 몬티홀 딜레마</a>)</p>
<table>
<thead>
<tr>
<th style="text-align:center"></th>
<th style="text-align:center">  Prior  </th>
<th style="text-align:center">  Likelihood  </th>
<th style="text-align:center">  Evidence  </th>
<th style="text-align:center">  Posterior  </th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">1번</td>
<td style="text-align:center">\( {1 \over 1000} \)</td>
<td style="text-align:center">\( {1 \over 999} \)</td>
<td style="text-align:center">\( {1 \over 999} \)</td>
<td style="text-align:center">\( {1 \over 1000} \)</td>
</tr>
<tr>
<td style="text-align:center">2번</td>
<td style="text-align:center">\( {1 \over 1000} \)</td>
<td style="text-align:center">0</td>
<td style="text-align:center">\( {1 \over 999} \)</td>
<td style="text-align:center">0</td>
</tr>
<tr>
<td style="text-align:center">3번</td>
<td style="text-align:center">\( {1 \over 1000} \)</td>
<td style="text-align:center">0</td>
<td style="text-align:center">\( {1 \over 999} \)</td>
<td style="text-align:center">0</td>
</tr>
<tr>
<td style="text-align:center">\( \vdots \)</td>
<td style="text-align:center">\( \vdots \)</td>
<td style="text-align:center">\( \vdots \)</td>
<td style="text-align:center">\( \vdots \)</td>
<td style="text-align:center">\( \vdots \)</td>
</tr>
<tr>
<td style="text-align:center">1000번</td>
<td style="text-align:center">\( {1 \over 1000} \)</td>
<td style="text-align:center">1</td>
<td style="text-align:center">\( {1 \over 999} \)</td>
<td style="text-align:center">\( {999 \over 1000} \)</td>
</tr>
</tbody>
</table>
<p>위의 예에서 약간 감을 잡았다면 이번에는 사회자가 문을 2번 하나만 연다고 생각해보자. 위 예제와 prior와 evidence는 동일하고, likelihood의 값이 달라서 posterior도 달라진다.</p>
<p>Likelihood : P(B|A)</p>
<ul>
<li>1번에 페라리가 있을때, 2 ~ 1000번 문(999개)에서 2번 문을 열 확률은 \( { 1 \over {999}C{1} } \)</li>
<li>2번에 페라리가 있을때, 2 ~ 999번 문을 열 확률은 0.</li>
<li>3번에 페라리가 있을때, 2번 문을 열 확률은 \( { 1 \over {998}C{1} } \) (4 ~ 999도 동일)</li>
<li>1000번에 페라리가 있을때, 2번 문을 열 확률은 3번의 사례와 같음(위 예제와 형식을 맞춰 놓기 위해 따로 써준 것일 뿐이다)</li>
</ul>
<p>Posterior : P(A|B), 사회자가 문을 2번만 열였을 때</p>
<ul>
<li>1번 문 뒤에 페라리가 있을 확률 : \( {1 \over 1000} \)</li>
<li>2번 문 뒤에 페라리가 있을 확률 : 0</li>
<li>3번 뒤에 페라리가 있을 확률 : \( {999 \over 1000 \times 998} \) (4 ~ 999도 동일)</li>
<li>1000번 뒤에 페라리가 있을 확률 : 3번과 같음</li>
</ul>
<p>두 예제가 같은 결론을 내고 있다는 것을 파악하면 좋을 것 같다. 마찬가지로 1000개가 아니라 3개로 문 개수가 줄어도 똑같은 결론을 낸다. 따라서 문을 무조건 바꾸는게 합리적이다.</p>
<blockquote>
<p>처음에 1번 문을 선택한 문의 당첨 확률이 1/1000이고, 나머지 문들의 당첨 확률이 999/1000이다. 애초에 2개의 집합으로 나누고, 거기서 나머지 문들에 속하는 집합에서 문들을 계속 제거해도(열어도) 나머지 문들의 집합에서의 당첨확률이 여전히 999/1000이기 때문에 해당 집합의 남아있는 문들(1번 말고)이 균등하게 확률을 받는 거라고 설명하는 사람도 있다.</p>
</blockquote>
<table>
<thead>
<tr>
<th style="text-align:center"></th>
<th style="text-align:center">  Prior  </th>
<th style="text-align:center">  Likelihood  </th>
<th style="text-align:center">  Evidence  </th>
<th style="text-align:center">  Posterior  </th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">1번</td>
<td style="text-align:center">\( {1 \over 1000} \)</td>
<td style="text-align:center">\( {1 \over 999} \)</td>
<td style="text-align:center">\( {1 \over 999} \)</td>
<td style="text-align:center">\( {1 \over 1000} \)</td>
</tr>
<tr>
<td style="text-align:center">2번</td>
<td style="text-align:center">\( {1 \over 1000} \)</td>
<td style="text-align:center">0</td>
<td style="text-align:center">\( {1 \over 999} \)</td>
<td style="text-align:center">0</td>
</tr>
<tr>
<td style="text-align:center">3번</td>
<td style="text-align:center">\( {1 \over 1000} \)</td>
<td style="text-align:center">\( {1 \over 998} \)</td>
<td style="text-align:center">\( {1 \over 999} \)</td>
<td style="text-align:center">\( {1 \over 1000} \times {999 \over 998} \)</td>
</tr>
<tr>
<td style="text-align:center">\( \vdots \)</td>
<td style="text-align:center">\( \vdots \)</td>
<td style="text-align:center">\( \vdots \)</td>
<td style="text-align:center">\( \vdots \)</td>
<td style="text-align:center">\( \vdots \)</td>
</tr>
<tr>
<td style="text-align:center">1000번</td>
<td style="text-align:center">\( {1 \over 1000} \)</td>
<td style="text-align:center">\( {1 \over 998} \)</td>
<td style="text-align:center">\( {1 \over 999} \)</td>
<td style="text-align:center">\( {1 \over 1000} \times {999 \over 998} \)</td>
</tr>
</tbody>
</table>
<h3 id="naive-bayes의-원리--활용-상의-제약점">Naive Bayes의 원리 &amp; 활용 상의 제약점</h3>
<p>Bayesian이 한계에 부딪히는 포인트 &amp; 극복 방안</p>
<p>&lt;데이터마이닝 수업&gt;</p>
<ul>
<li>데이터가 연속인 경우 : 이산확률밀도함수(p.d.f)는 구간의 확률을 구해야 하는데, 그냥 특정한 포인트에 대해서 확률 계산을 하고 사용하겠다.(틀렸지만 쓰겠다)</li>
</ul>
<blockquote>
<p>정확한 posterior 확률을 구하는게 목적이 아니라, 상대적인 비교가 목적이다. 따라서 대체가 가능하기 때문에 p.d.f의 함수값(높이)만을 비교해서 classification을 하겠다는 의도이다.</p>
</blockquote>
<ul>
<li>모든 변수가 독립이라는 가정을 이용해서 계산하는데, 하나의 변수의 확률이 0이면 전체 확률이 0이 되어버린다.
<ul>
<li>Original : \( P(A_i|C)={ N_{iC} \over N_C }  \)</li>
<li>Laplace : \( P(A_i|C)={ N_{iC}+1 \over N_C+k }  \)</li>
<li>m-estimate : \( P(A_i|C)={ N_{iC}+mp \over N_C+m }  \)
<ul>
<li><strong>k</strong> : number of distinct values of attribute \( A_i \)</li>
<li><strong>m</strong> : parameter; equivalnt sample size</li>
<li><strong>p</strong> : prior probability</li>
</ul>
</li>
</ul>
</li>
<li>독립 가정이 깨지면 Bayesian Belief Networks(BBN)이용</li>
</ul>
<h3 id="gaussian-mixture-modelgmm">Gaussian Mixture Model(GMM)</h3>
<p>데이터에 Latent variable이 있을 때 모델링 아이디어</p>
<ul>
<li>
<p>Y값이 몇 개의 Hidden 변수로 설명되는지에 초점 : bayesian도 latent를 찾아내기 위한 큰 그림</p>
</li>
<li>
<p>베이지안 관점에서 보면 시야가 달라진다</p>
</li>
<li>
<p>여러 분포가 섞인 그림을 보면, 직관적으로 3개로 나눠진 것 같다고 이해를 할 수 있다.(빨간 선을 가지고 역추적 한다) 봉 3개가 있는 그래프를 이용해서 lantent variable을 찾으면 3개의  데이터 묶음을 찾을 수 있지 않을까? (이번에는 %를 줄 수 있다.)</p>
</li>
</ul>
<blockquote>
<p>분포가 겹치는 애매한 부분에 대해 bayesian 개념으로 확률을 줘 이야기 할 수 있다.</p>
</blockquote>
<h3 id="gmm-vs-k-means---k-means는-사실-gmm의-특별한-케이스spherical-cluster일-뿐이다">GMM vs. k-Means - k-means는 사실 GMM의 특별한 케이스(spherical cluster)일 뿐이다?</h3>
<ul>
<li>EM : 데이터가 추가된 것으로 기존의 값을 확인해보고, 업데이트 하는 과정이 베이지안 스타일이다.</li>
<li>%를 이야기해줘야 할때, gray area(구획이 잘 되어있는 상태에서)를 판단할 때 GMM이 의미가 있다.</li>
<li>K-meas는 centroid 찾는 작업이고, GMM은 centroid를 찾은 후 variance를 찾는 작업이다.
(이해 못함)</li>
</ul>
<h3 id="em과-latent-variable---latent-variable을-가정하면-얻을-수-있는-장점">EM과 Latent variable - latent variable을 가정하면 얻을 수 있는 장점</h3>
<ul>
<li>
<p>Bayesian에서 Evidence를 계산하는 작업은 최대한 피하는 것이 원칙 (why?)</p>
</li>
<li>
<p>Onsite :</p>
</li>
<li>
<p>Latent variable : intell을 알면, 기존 5개의 변수를 이용해서 latent variable 찾는 공식을 알고 있다고 한다면, 변수 하나가 없어도 비슷하게 추정할 수 있을 것이다.</p>
</li>
<li>
<p>각각의 분포알고, 전체의 분포를 알고있으나 marginal 분포는 알기가 어렵다</p>
</li>
<li>
<p>실제로 latent가 없지만 있다고 가정(평균값 같은 것으로)하고 계속 데이터를 추가하면서 보정하면서, 결국 4개의 변수를 가지고 onsite를 계산할 수 있다.</p>
</li>
</ul>
<h3 id="discussion-points-data-preprocessing--feature-selection">Discussion points: Data preprocessing &amp; Feature selection</h3>
<p>데이터 모델링은 <strong>모델</strong>에서 출발하는 것이 아니라, <strong>데이터</strong>에서 출발한다.</p>
<ul>
<li>어떤 <strong>모델</strong>을 쓰겠다는 생각은 결국 데이터를 어떻게 pre-processing하겠다는 생각과 연결되어 있음.</li>
<li>데이터 전처리와 피쳐 셀럭션을 사람들이 잘못알고 계산을 하고 있다고 생각한다.</li>
<li>5개의 marginal 분포를 알면 4개의 변수를 알고, 1개가 missing일 때 1개를 알 수 있다.</li>
<li>모든 작업은 <strong>latent variable</strong>을 찾아내려고 하는 것이고, Latent 1, Latent 2, Latent 3을 알고 있다면 모르는 대표값 찾는 것은 일도 아니다.</li>
</ul>

  
    
    <div class="post-toc">
      <span class="title">Contents</span>
      <nav id="TableOfContents">
  <ul>
    <li><a href="#section-1-k-nearest-neighbor">Section 1. K-Nearest Neighbor</a></li>
    <li><a href="#section-2-k-means">Section 2. K-Means</a></li>
    <li><a href="#section-3-dimensionality-reduction">Section 3. Dimensionality reduction</a></li>
    <li><a href="#section-4-side-note-bayesian">Section 4. Side Note: Bayesian</a>
      <ul>
        <li><a href="#bayesian-vs-frequentist---관점의-차이-계산의-차이-용도의-차이">Bayesian vs. Frequentist - 관점의 차이, 계산의 차이, 용도의 차이</a></li>
        <li><a href="#bayesian-아이디어가-적용되는-간단-예제1---몬티홀-딜레마">Bayesian 아이디어가 적용되는 간단 예제1 - 몬티홀 딜레마</a></li>
        <li><a href="#naive-bayes의-원리--활용-상의-제약점">Naive Bayes의 원리 &amp; 활용 상의 제약점</a></li>
        <li><a href="#gaussian-mixture-modelgmm">Gaussian Mixture Model(GMM)</a></li>
        <li><a href="#gmm-vs-k-means---k-means는-사실-gmm의-특별한-케이스spherical-cluster일-뿐이다">GMM vs. k-Means - k-means는 사실 GMM의 특별한 케이스(spherical cluster)일 뿐이다?</a></li>
        <li><a href="#em과-latent-variable---latent-variable을-가정하면-얻을-수-있는-장점">EM과 Latent variable - latent variable을 가정하면 얻을 수 있는 장점</a></li>
        <li><a href="#discussion-points-data-preprocessing--feature-selection">Discussion points: Data preprocessing &amp; Feature selection</a></li>
      </ul>
    </li>
  </ul>
</nav>
    </div>
    <div style='padding:15px;'>
    </div>
    
  </section>
  <div class="post-meta-code">
    <div class="desc">
      
      <a href="mailto:uqpuark@gmail.com">uqpuark</a>
      
      님이
      <span class="highlight">2021년 02월 18일 15시 30분</span> 
      에 작성한 글입니다.
    </div>
    <div style="padding-left: 16px">
    데이터 사이언티스트를 꿈꾸고 있습니다. 수학, 통계학에 대한 질문이나 의견을 나누고 싶습니다. 
    </div>
    <div class="desc">
      
      <div class="desc">
        <span class="fixed-desc">[카테고리]</span>
        
        
      </div>
      
      <div class="desc">
        <span class="fixed-desc">[태그]</span>
        
      </div>
    </div>
  </div>  
  <div class="recommend-articles">
    다음으로 읽을만한 글입니다.
    <ul>
      
      <li>
        <a href="https://uqpuark.github.io/math/hat_matrix/" rel="prev">
          <span>Hat_matrix</span>
        </a>
      </li>
      
      
    </ul>
  </div>
</div>

<script src="https://utteranc.es/client.js"
        repo="uqpuark/uqpuark.github.io"
        issue-term="pathname"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script>

<div class="go-top">
  <a href="#" class="go-top-button">
    <i class="fa fa-angle-double-up"></i>
    <span>위로</span>
  </a>
</div>
<footer class="footer">
  <div class="share">
      <a href="https://github.com" title="Github" target="_blank"><i class="fa fa-github fa-3x"></i></a>
  </div>
  COPYRIGHT (C) <a href="https://blog.lulab.net">DONGGEUN,BANG (LUBANG).</a><br />
  ALL RIGHTS RESERVED.
<script>
window.store = {
    
    
}
</script>

<script src="/js/lunr.min.js"></script>
<script src="/js/search.js"></script>
</footer>
</body>
</html>
