<!DOCTYPE html>
<html>
<head>
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>[ESL] CH2 Overview of Supervised Learning  | 데이터 사이언스 블로그</title>
  <meta name="description" content="대충 넘어 갔던 개념을 자세하게 따져보는 블로그 '[ESL] CH2 Overview of Supervised Learning'을 한 번 살펴보세요.">
  <meta property="og:title" content="[ESL] CH2 Overview of Supervised Learning">
  
  <meta property="og:type" content="article">
  <meta property="article:published_time" content="2021-02-13">
  
  <meta property="og:description" content="대충 넘어 갔던 개념을 자세하게 따져보는 블로그 '[ESL] CH2 Overview of Supervised Learning'을 한 번 살펴보세요.">
  <meta property="og:url" content="https://uqpuark.github.io/esl/esl-ch02-overview/">
  <meta property="og:site_name" content="데이터 사이언스 블로그">
  
  <meta property="og:image" content="https://uqpuark.github.io/images/thumbnail.png">
  
  
  <meta property="og:tags" content="ESL">
  
  <meta property="og:tags" content="ML">
  
  <meta property="og:tags" content="통계학">
  
  <meta property="og:tags" content="Least Square">
  
  <link rel="icon" href="/favicon.ico" type="image/x-icon">
  <link rel="canonical" href="https://uqpuark.github.io/esl/esl-ch02-overview/">
  <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
  <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.6/styles/agate.min.css">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Noto+Sans+KR&display=swap">
  <link rel="stylesheet" href="/css/styles.css">
  <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.6/highlight.min.js"></script>
  <script>hljs.initHighlightingOnLoad();</script>
  
  
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-189694109-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());
    gtag('config', 'UA-189694109-1');
  </script>
  
  
  <script type="text/javascript">
  function toggle_visibility(id) {
    var e = document.getElementById(id);
    if (e.className === 'menu')
      e.className = 'menu hidden';
    else
      e.className = 'menu';
  }
  </script>
</head>
<body>
  <div class="navbar">    
    <div class="logo">
      <a href="/">
        <img src="/images/logo.png" height="35px" />
      </a>
    </div>
    <div class="burger">
      <button onclick="toggle_visibility('menu')">
        <i class="fa fa-bars" aria-hidden="true"></i> 메뉴
      </button>
    </div>
    <div id="menu" class="menu hidden">
      <ul>
        <li><form id="search"
    action='' method="get">
    <label hidden for="search-input">Search site</label>
    <input type="text" id="search-input" name="query"
    placeholder="search or jump to...">
    <input type="submit" value="search">
</form>

</li>
        <li><a href="/categories">카테고리</a></li>
        <li><a href="/tags">태그</a></li>


      </ul>
      <input class="search" id="search-input" type="search" placeholder="검색어" value="">
    </div>
  </div>
  <div class="container">    


<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css" integrity="sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X" crossorigin="anonymous">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.js" integrity="sha384-g7c+Jr9ZivxKLnZTDUhnkOnsh30B4H0rpLUpJ4jAIKs4fnJI+sEnkvrMWph2EDg4" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/contrib/auto-render.min.js" integrity="sha384-mll67QQFJfxn0IYznZYonOWZ644AWYC+Pt2cHqMaRhXVrursRwvLnLaebdGIlYNa" crossorigin="anonymous"
    onload="renderMathInElement(document.body);"></script>


<div class="post">
  <div class="post-title">
    <a href="https://uqpuark.github.io/esl/esl-ch02-overview/">
      <div class="post-meta">
        <time>2021년 02월 13일 23시 10분</time>
        <h1>[ESL] CH2 Overview of Supervised Learning</h1>
      </div>
    </a>
  </div>
  <section class="post-content">
    <h2 id="시작">시작</h2>
<p>CH2에서는 <strong>Least Squares</strong>와 <strong>Nearest Neighbors</strong>을 이용하여 앞으로 공부할 내용을 쭉 훑어본다. 두가지 방법 모두 Supervised Learning에 속하지만 전자는 데이터를 하나하나씩 보고, 후자는 데이터를 묶음으로 보는 관점을 가지고 있다.</p>
<blockquote>
<p>일반적으로 머신러닝은 크게 <strong>Supervised</strong>와 <strong>Unsupervised</strong>로 분류된다. 일반적으로 Y값, 즉 데이터의 클래스값을 알면 전자 모르면 후자로 나누어진다.</p>
</blockquote>
<blockquote>
<p>하지만 데이터 전처리의 관점에서는 데이터를 하나씩 다루는지, 묶음단위(group)로 다루는지에 따라 바라볼 수도 있다. 전자는 regression 후자는 KNN, K-Means일 것이다.</p>
</blockquote>
<h2 id="21--22">2.1 ~ 2.2</h2>
<h3 id="input과-output">input과 output</h3>
<p>input과 output을 지칭하는 용어가 하도 많아서 한번 정리하고 간다. 머신러닝은 통계학 용어와 다르게 사용하는 경우가 많아서 용어 정리가 필요하다.</p>
<ul>
<li><strong>input</strong> : X, feature, attribute, factor, predictor, independent variables, regressor</li>
<li><strong>output</strong> : Y, record, instance, target, observations responses, dependent variables, regressand</li>
</ul>
<h3 id="variable-types">Variable Types</h3>
<ul>
<li>
<p><strong>quantitative</strong> : output이 정량적, 예) 온도같이 연속적인 값<br>
<strong>qualitative(categorical, discrete)</strong> : output이 정성적(범주형), 예) Iris 종류(Virginica, Setosa, and Versicolor), 0/1</p>
</li>
<li>
<p><strong>regression</strong> : quantitative ouputs을 예측할 때의 명칭<br>
<strong>classification</strong> : qualitative ouputs을 예측할 때의 명칭</p>
</li>
<li>
<p>inputs도 측정 방식에 따라 정량적, 정석적으로 나뉜다. 각각에 대해 적절한 방법이 있다.</p>
</li>
<li>
<p><strong>ordered categorical</strong> variables : small, medium, large와 같이 범주형 + 순서가 있는 변수, 일반적인 거리(Euclidean distance) 개념에 맞지 않을 수 있다.</p>
</li>
<li>
<p>qualitative variables는 숫자로 표현한다 : 2개의 클래스(성공, 실패)에 대해 0 or 1, -1 or 1 등으로 코딩한다. 이러한 numeric codes를 <strong>targets</strong>이라고 부른다.
<strong>dummy variables</strong> : K개의 클래스를 가진 범주형 변수(K-level qualitative variable)는 K개의 binary variables(or bits)로 표현된다. S, M, L 3개의 클래스값이 있으면 각각 1 0 0, 0 1 0, 0 0 1로 표현할 수 있다.</p>
</li>
</ul>
<blockquote>
<p>더미 변수는 symmetric in the levels of the factor(요인 수준에 대해 대칭)</p>
</blockquote>
<blockquote>
<p>일반적으로 더미 변수를 사용할 때는 K-1개의 변수를 사용한다. S, M, L의 경우 각각 0 0, 1 0, 0 1로 표현한다. (1) 0 0, (0) 1 0, (0) 0 1이라고 생각하면 될 듯?</p>
</blockquote>
<blockquote>
<p>머신러닝에서 더미 변수를 사용하는 방법을 one-hot-encoding이라고 한다. 통계학이나 계량경제학에서 더미변수를 사용하는 것과 같으니 헷갈리지 말자.</p>
</blockquote>
<ul>
<li>
<p>\( \hat{Y} \) : good prediction of the ouput \( Y \)<br>
\( \hat{G} \) : set \( \mathcal{G} \)에 있는 값을 사용하여 추정</p>
</li>
<li>
<p>\( \hat{G} \), 2-클래스 할당 방법 : \( \hat{Y} \)을 [0,1] 사이의 값으로 추정하고, \( \hat{y} &gt; 0.5 \)를 기준으로 분류할 수 있다.</p>
</li>
</ul>
<blockquote>
<p>1에 가까울 수록 실제로 1일 확률이 높다고 할 수 있지 않을까? 라는 개념이 사용될 수 있다.(확률의 공리를 만족한다면?, 수학적으로 엄밀한 것은 아니다)</p>
</blockquote>
<h2 id="23">2.3</h2>
<h3 id="linear-models">Linear Models</h3>
<p>Linear model은 parameters가 선형인 모델을 말한다. \( X^2 \)가 항에 들어가도 \( \beta \)가 선형이면 선형 모형이다. 선형 모형은 형식이 간단해서 해석하기가 쉽고, 비선형 모형 보다 피팅하기가 쉽고, 계산이 덜 복잡해서 배운다.
\( X^T=(X_1, X_2, \cdots, X_p) \)가 주어지면 (\( X^T \)는 벡터) 선형 모델은 다음과 같다.</p>
<p>$$ \hat{Y}=\sum_{j=1}^p \hat{\beta_0}+X_j\hat{\beta_j}  $$
\( \hat{\beta_1} \) : slope(기울기), X의 coefficient(계수)이다.<br>
\( \hat{\beta_0} \) : intercept(절편)을 \( X_0 = 1 \)라고 생각하면 벡터 형식으로 다음과 같다.
$$ \hat{Y}= X^T\hat{\beta} $$</p>
<blockquote>
<p>\( X=(X_1, X_2, \cdots, X_p) \)로 정의하면, \( \hat{Y}= X\hat{\beta} \) 이다.</p>
</blockquote>
<ul>
<li>\( \beta : p \times N \) matrix이면 \( \hat{Y}\)는 \( N \times 1 \)(N-벡터)</li>
<li>P+1차원에서 \( (X, \hat{Y}) \)는 hyperplane(P차원)이다. 상수항이 X에 포함되어있으면 초평면은 원점을 포함하고 subspace가 된다. 그렇지 않으면 아핀공간이 된다.(아핀 공간 개념을 잘 몰라서 그냥 넘어감)</li>
</ul>
<h3 id="least-square">Least Square</h3>
<p>$$  \underset{\beta}{minimize}\ RSS(\beta)=\sum_{i=1}^N(y_i-x_i^T\beta)^2 $$<br>
residual sum of squares를 최소화 하는 \( \beta \)를 찾는 방법이다. RSS는 이차식이고, minimum이 항상 존재하지만 unique는 보장하지 않는다.(참고로 통계학에서는 least square, 머신러닝에서는 normal equation, 계량경제학에서는 OLS라고 부른다) 행렬로 표현하면 다음과 같다.</p>
<p>$$ \bold{y}=\bold{X}\beta + \varepsilon $$
$$ RSS(\beta)=\left( \bold{y}-\bold{X}\beta \right)^T\left(\bold{y}-\bold{X}\beta \right) $$
\( \bold{X} \) : \( N \times p \)행렬, 각각의 행이 하나의 input이다.<br>
\( \bold{y }\) : \( N \)-vector, N개의 outputs( \( N \times 1 \) 행렬이라고 생각해도 큰일이 나지는 않는다)</p>
<blockquote>
<p>전체적인 형태
$$ \begin{pmatrix} y_{1} \\\ y_{2} \\\ \vdots \\\ y_{n} \end{pmatrix}=\begin{pmatrix} 1 &amp; x_{11} &amp; x_{12} &amp; \cdots &amp; x_{1p} \\\ 1 &amp; x_{21} &amp; x_{22} &amp; \cdots &amp; x_{2p}\\\ \vdots &amp; \vdots &amp; \ddots &amp; \vdots\\\ 1 &amp; x_{N1} &amp; x_{N2} &amp; \cdots &amp; x_{Np} \end{pmatrix} \begin{pmatrix} \beta_0 \\\ \beta_1 \\\ \beta_2 \\\ \vdots \\\ \beta_p \end{pmatrix} + \begin{pmatrix} \varepsilon_0 \\\ \varepsilon_1 \\\ \varepsilon_2 \\\ \vdots \\\ \varepsilon_p \end{pmatrix} $$</p>
</blockquote>
<p>\( \beta \)에 대해 미분하면 normal equation을 얻는다.(convex이기 때문에 미분값이 최솟값을 갖는다)
$$ \bold{X}^T\left( \bold{y}-\bold{X}\beta \right)=0  $$</p>
<p>\( \bold{X}^T\bold{X} \)가 nonsingular이면 다음과 같은 unique solution이 나온다.
$$ \hat{\beta}=\left( \bold{X}^T\bold{X} \right)^{-1}\bold{X}^T\bold{y} $$</p>
<ul>
<li>세부 수식
<ul>
<li>\( f := \lVert y-X\beta \rVert_2 \)<br>
\( \quad = \left( \bold{y}-\bold{X}\beta \right)^T\left( \bold{y}-\bold{X}\beta \right) \)<br>
\( \quad = (\bold{y}^T-\beta^T\bold{X}^T)(\bold{y}-\bold{X}\beta) \)<br>
\( \quad = \bold{y}^T\bold{y}-\bold{y}^T\bold{X}\beta-\left( \bold{X}\beta \right)^T\bold{y}+\left( \bold{X}\beta^T\bold{X}\beta \right) \)<br>
\( \quad = \bold{y}^T\bold{y}-2\bold{y}^T\bold{X}\beta+\beta^T\bold{X}^T\bold{X}\beta \)</li>
<li>\( {\partial f \over\partial \beta} = 0 -2\bold{y}^T\bold{X}+2\bold{X}^T\bold{X}\beta = 0 \)    정리하면 위의 값이 나온다.</li>
</ul>
</li>
</ul>
<h3 id="nearest-neighbor-methods">Nearest-Neighbor Methods</h3>
<p>\( N_k(x) \) : x와 가까운 k개의 이웃들로 이루어진 집합.<br>
파랑색을 0으로, 주황색을 1로 코딩했을때 이웃의 평균이 0.5보다 높으면 주황으로 분류한다.(식 보다는 설명이 쉬워서 식 생략)</p>
<ul>
<li>
<p>voronoi tessellation : 1NN으로 분류했을때, 같은 class로 분류된 점들을 다각형안에 무조건 집어넣을 수 있다.(하지만 실제 test data가 그 다각형 안에 올바르게 들어가지는 않음) decision boundary가 얘로 나타난다.</p>
</li>
<li>
<p>\( {N \over k} \) : effective number of parameters of k-NN, 원래 k-NN의 parameter는 k 하나이다. 그러나 k를 다루기 보다는 \( {N \over k} \)를 다루는게 좋다. 일반적으로 p보다 크고, k가 증가하면 감소한다. 이웃 집합들이 겹치지 않을 때, \( {N \over k} \)개의 이웃들이 존재하고, 각각의 이웃에 대해서 하나의 fit을 할수 있다.</p>
</li>
</ul>
<blockquote>
<p>데이터 전처리의 관점에서 쳐다보면, 데이터(N)가 100만개 있다고 했을때, 데이터가 너무 많아서 데이터를 1만개나 10만개로 줄이고 싶은 상황이 있을 것이다. k-nn을 활용한다면 전자의 경우 k=100, k=10이 될것이다. 이러한 경우, 우리가 중요하게 봐야하는 숫자는 k가 아니라 우리가 최종적으로 다룰 데이터의 갯수(1만, 10만)가 되고, 이것이 \( {N \over k} \)이다. 그러니까 k를 정하는 게 아니라 \( {N \over k} \)를 정하고나서 그에 맞는 k는 자연스럽게 나오는 것이라고 볼 수 있다.</p>
</blockquote>
<h3 id="scenario">Scenario</h3>
<p>Scenario 1: 각각의 클래스(파랑, 주황)는 각각 노말 분포로 생성되었고, 서로 평균이 다르고 상관관계가 없다.<br>
Scenario 2: 각각의 클래스(파랑, 주황)는 하나당 10개의 분포(분산이 작음)의 혼합이고, 10개의 분포는 서로 평균이 다르고, 정규분포를 따른다. (<a href="https://stats.stackexchange.com/questions/81197/can-someone-please-explain-to-me-what-the-particular-scenarios-mean">시각적으로 이해를 돕기 위한 링크</a>)</p>
<p>least square는 시나리오1의 상황에 적절한 방법이고, k-nn은 시나리오2에 적절한 분류 방법이라고 한다. least square는 직선으로 decision boundary가 형성되므로 low variance, high bias를 갖는다. 반면, knn은 high variance, low bias를 갖는다. (p17에서 \( N(( 1, 0)^T , {\bold{I} \over 5}) \)으로 데이터를 생성하는데, 그냥 예시를 들기위해 I/5로 나눈 것이다.)</p>
<ul>
<li>Neural network models consist of sums of nonlinearly transformed linear models.(p18) : 뉴럴 네트워크는 선형 모형의 결합이다. 이러한 사실을 알고 있어야 한다.</li>
</ul>
<h2 id="24-statistical-decision-theory">2.4 Statistical Decision Theory</h2>
<p>SDT, 통게적 결정 이론이라고 부른다.</p>

  
    
    <div class="post-toc">
      <span class="title">Contents</span>
      <nav id="TableOfContents">
  <ul>
    <li><a href="#시작">시작</a></li>
    <li><a href="#21--22">2.1 ~ 2.2</a>
      <ul>
        <li><a href="#input과-output">input과 output</a></li>
        <li><a href="#variable-types">Variable Types</a></li>
      </ul>
    </li>
    <li><a href="#23">2.3</a>
      <ul>
        <li><a href="#linear-models">Linear Models</a></li>
        <li><a href="#least-square">Least Square</a></li>
        <li><a href="#nearest-neighbor-methods">Nearest-Neighbor Methods</a></li>
        <li><a href="#scenario">Scenario</a></li>
      </ul>
    </li>
    <li><a href="#24-statistical-decision-theory">2.4 Statistical Decision Theory</a></li>
  </ul>
</nav>
    </div>
    <div style='padding:15px;'>
    </div>
    
  </section>
  <div class="post-meta-code">
    <div class="desc">
      
      <a href="mailto:uqpuark@gmail.com">uqpuark</a>
      
      님이
      <span class="highlight">2021년 02월 13일 23시 10분</span> 
      에 작성한 글입니다.
    </div>
    <div style="padding-left: 16px">
    데이터 사이언티스트를 꿈꾸고 있습니다. 수학, 통계학에 대한 질문이나 의견을 나누고 싶습니다. 
    </div>
    <div class="desc">
      
      <div class="desc">
        <span class="fixed-desc">[카테고리]</span>
        
        
        <a href="https://uqpuark.github.io/categories/esl">#ESL</a>
        
      </div>
      
      <div class="desc">
        <span class="fixed-desc">[태그]</span>
        
        
        <a href="https://uqpuark.github.iotags/esl">#ESL</a>
        
        <a href="https://uqpuark.github.iotags/ml">#ML</a>
        
        <a href="https://uqpuark.github.iotags/%ED%86%B5%EA%B3%84%ED%95%99">#통계학</a>
        
        <a href="https://uqpuark.github.iotags/least-square">#Least Square</a>
        
        
      </div>
    </div>
  </div>  
  <div class="recommend-articles">
    다음으로 읽을만한 글입니다.
    <ul>
      
      <li>
        <a href="https://uqpuark.github.io/esl/esl-ch01-introduce/" rel="prev">
          <span>[ESL] CH1 Introduce </span>
        </a>
      </li>
      
      
      <li>
        <a href="https://uqpuark.github.io/esl/esl-ch3-regression/" rel="next">
          <span>[ESL] CH3 Linear Methods for Regression</span>
        </a>
      </li>
      
    </ul>
  </div>
</div>

<script src="https://utteranc.es/client.js"
        repo="uqpuark/uqpuark.github.io"
        issue-term="pathname"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script>

<div class="go-top">
  <a href="#" class="go-top-button">
    <i class="fa fa-angle-double-up"></i>
    <span>위로</span>
  </a>
</div>
<footer class="footer">
  <div class="share">
      <a href="https://github.com" title="Github" target="_blank"><i class="fa fa-github fa-3x"></i></a>
  </div>
  COPYRIGHT (C) <a href="https://blog.lulab.net">DONGGEUN,BANG (LUBANG).</a><br />
  ALL RIGHTS RESERVED.
<script>
window.store = {
    
    
}
</script>

<script src="/js/lunr.min.js"></script>
<script src="/js/search.js"></script>
</footer>
</body>
</html>
